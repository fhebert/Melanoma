{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Melanoma recognition using transfer learning","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nIn this notebook, the main steps of a possible way to use transfer learning for melanoma recognition are summarized. The dataset used is available on Kaggle: https://www.kaggle.com/nroman/melanoma-external-malignant-256\nThis dataset contains almost 40,000 images (256 x 256 pixels) of melanoma and harmless skin marks.\n\nThe main objective of this notebook is to provide a way to build an algorithm to recognize melanoma on photographs. For this purpose, I choose to use transfer learning, which consists in using a pre-trained algorithm, adapting a bit its structure for the data and fine-tuning it using a training dataset. The main advantage of this method is that it enables to use an already proven algorithm, which has been trained for a very long time and which has already learned to recognize multiple image patterns in a very large dataset. \n\nIn the following, the ResNext50 model is used (https://pytorch.org/hub/pytorch_vision_resnext/). This CNN is namely more efficient than numerous pre-trained alternatives available for transfer learning, and was shown to be among the most accurate ones on the famous ImageNet dataset.\n\nRunning this notebook on Kaggle allows to use a GPU, which is very useful to speed up the CNN work. We will have to indicate to PyTorch which objects should be transferred to the GPU (mainly the model and the image and target values tensors). Thus, each time the .cuda() function appears in the notebook, it means the object to which it is applied is transferred to the GPU.","metadata":{}},{"cell_type":"markdown","source":"## Data importation and processing\n\nWe first import the main libraries needed in the following. The neural network will be trained using the PyTorch library.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T19:02:19.544479Z","iopub.execute_input":"2022-02-01T19:02:19.544846Z","iopub.status.idle":"2022-02-01T19:02:21.847734Z","shell.execute_reply.started":"2022-02-01T19:02:19.544763Z","shell.execute_reply":"2022-02-01T19:02:21.846959Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"We introduce below the MelanomaDataset class, which is a subclass of the PyTorch Dataset class and a helper to build the datasets for the training, validation and evaluation steps. This class takes the following arguments:\n- path: path to the folder containing the data\n- mode: \"train\", \"val\" or \"test\", depending on the dataset we want to build\n- frac_val: fraction of the whole dataset which should be kept for validation\n- frac_test: fraction of the whole dataset which should be kept for evaluation\n- random_state: seed to fix the train / val / test splitting of the dataset and to obtain reproducible results.\n\nAs any subclass of the Dataset class, this class must implement three methods: init, len and getitem. The init method only aims at initializing an instance of the class. The len method returns the number of instances in the dataset. Finally, the getitem method takes as argument an index and returns the corresponding element (both the image and the target value) of the dataset.\nNote that the result given by these two methods depends on the mode initially selected when creating the class instance. If the value of mode is \"train\" (resp. \"val\", \"test\"), then the result of len is the number of instances in the training (resp. validation, evaluation) dataset. Similarly, the getitem method returns the element at position id in the training, validation or evaluation dataset.\n\nAnother method called train_val_test_split is implemented. This simply aims at splitting the dataset in three independent parts: one for training, one for validation, one for evaluation.\n\nNote that the images are preprocessed; they are namely cropped to a square of size 224 x 224 and normalized using mean [0.485, 0.456, 0.406] and standard deviation [0.229, 0.224, 0.225]. This is indeed required by the network that will be used.","metadata":{}},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, path, mode=\"train\", frac_val=0.2, frac_test=0.2, random_state=1234):\n        self.path = path\n        self.mode = mode\n        self.frac_val = frac_val\n        self.frac_test = frac_test\n        self.random_state = random_state\n        labels = pd.read_csv(path+\"/train_concat.csv\",header=0,sep=\",\")\n        image_name = labels[\"image_name\"]\n        target = labels[\"target\"]\n        self.image_name = image_name\n        self.target = target\n        path_images = path+\"/train/train\"\n        self.path_images = path_images\n        xtrain, ytrain, xval, yval, xtest, ytest = self.__train_val_test_split__()\n        self.train = (xtrain, ytrain)\n        self.val = (xval, yval)\n        self.test = (xtest, ytest)\n        self.preprocess = transforms.Compose([\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    def __len__(self):\n        if self.mode==\"train\":\n            return len(self.train[0])\n        if self.mode==\"val\":\n            return len(self.val[0])\n        if self.mode==\"test\":\n            return len(self.test[0])\n    def __getitem__(self, id):\n        if self.mode==\"train\":\n            image_id = self.train[0].iloc[id]\n            file = self.path_images+\"/\"+image_id+\".jpg\"\n            x = self.preprocess(Image.open(file))\n            y = self.train[1].iloc[id]\n            return x, y\n        if self.mode==\"val\":\n            image_id = self.val[0].iloc[id]\n            file = self.path_images+\"/\"+image_id+\".jpg\"\n            x = self.preprocess(Image.open(file))\n            y = self.val[1].iloc[id]\n            return x, y\n        if self.mode==\"test\":\n            image_id = self.test[0].iloc[id]\n            file = self.path_images+\"/\"+image_id+\".jpg\"\n            x = self.preprocess(Image.open(file))\n            y = self.test[1].iloc[id]\n            return x, y\n    def __train_val_test_split__(self):\n        nval = round(self.frac_val * len(self.image_name))\n        ntest = round(self.frac_test * len(self.image_name))\n        xtrain, xtest, ytrain, ytest = train_test_split(self.image_name, self.target,\n                                                        test_size=ntest, random_state=self.random_state)\n        xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain,\n                                                      test_size=nval, random_state=self.random_state)\n        return xtrain, ytrain, xval, yval, xtest, ytest","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:03:22.037601Z","iopub.execute_input":"2022-02-01T19:03:22.037859Z","iopub.status.idle":"2022-02-01T19:03:22.054564Z","shell.execute_reply.started":"2022-02-01T19:03:22.037829Z","shell.execute_reply":"2022-02-01T19:03:22.053858Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"The instances of the MelanomaDataset corresponding to the training, validation and evaluation steps are now created and passed to the DataLoader class, which will enable to load the data as batches. Here the batch size is chosen to be 8, mainly for RAM issues (16 was already too much).","metadata":{}},{"cell_type":"code","source":"path = \"../input/melanoma-external-malignant-256\"\ntraindata = MelanomaDataset(path,\"train\")\nvaldata = MelanomaDataset(path,\"val\")\ntestdata = MelanomaDataset(path,\"test\")\ntrain = DataLoader(traindata,batch_size=8,shuffle=True)\nval = DataLoader(valdata,batch_size=8,shuffle=False)\ntest = DataLoader(testdata,batch_size=8,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:03:25.586738Z","iopub.execute_input":"2022-02-01T19:03:25.586990Z","iopub.status.idle":"2022-02-01T19:03:25.765087Z","shell.execute_reply.started":"2022-02-01T19:03:25.586961Z","shell.execute_reply":"2022-02-01T19:03:25.764378Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Model training\n\nThe ResNext50 model is now loaded. Only a tiny modification is performed to its architecture. The original ResNext50 model ends with a linear (or fully connected) layer, which has 2048 input features and outputs 1000 features, since the dataset on which it was trained had 1000 classes. Here, we replace this layer with a layer taking as input 2048 features and outputing 1 feature. The Sigmoid activation function is then added on top, to obtain the probability for each image to correspond to a melanoma.","metadata":{}},{"cell_type":"code","source":"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\nmodel.fc = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2048,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:09:58.075496Z","iopub.execute_input":"2022-02-01T19:09:58.075770Z","iopub.status.idle":"2022-02-01T19:10:10.688976Z","shell.execute_reply.started":"2022-02-01T19:09:58.075742Z","shell.execute_reply":"2022-02-01T19:10:10.688225Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\nDownloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/95.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"906c15e81b4a4752bd18583493f87b06"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=2048, out_features=1, bias=True)\n    (1): Sigmoid()\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"The fitting function is now implemented. First, a ModelCheckpoint class is implemented, which will enable to save the trained model at a given epoch if its validation loss is better than the previously saved best model. Its step method will be called after computing the loss on the validation sample, at the end of each epoch. This aims at saving a model as long as it improves itself, and preventing it to overfit (it will eventually overfit, but the best non-overfitted model will be saved).","metadata":{}},{"cell_type":"code","source":"class ModelCheckpoint():\n    def __init__(self, file_save):\n        self.val_loss = float(\"inf\")\n        self.file_save = file_save\n    def step(self, model, val_loss):\n        if val_loss < self.val_loss:\n            torch.save(model,self.file_save)\n            print(\"Validation loss improved from \"+str(round(self.val_loss,2))+\n                  \" to \"+str(round(val_loss,2))+\" ; current model saved to \"+self.file_save)\n            self.val_loss = val_loss\n\nimport gc\ndef fit(model,optim,train,val,n_epochs=10,file_save=\"/kaggle/working/cnn.pkl\"):\n    checkpoint = ModelCheckpoint(file_save=file_save)\n    loss_fn = torch.nn.BCELoss(reduction=\"sum\")\n    for i in range(n_epochs):\n        print(\"Epoch \" + str(i + 1) + \" - \", end=\"\")\n        train_loss = 0\n        k = 0\n        for input, target in train:\n            k = k + 1\n            if k % 500 == 0:\n                print(str(round(k * 100 / len(train), 2)) + \"% - \", end=\"\")\n                gc.collect()\n            optim.zero_grad()\n            output = model(input.cuda())\n            loss = loss_fn(output, target.view(-1, 1).to(torch.float32).cuda())\n            loss.backward()\n            optim.step()\n            train_loss = train_loss + loss\n        print(\"Training loss = \" + str(round(train_loss.item(), 2)) + \" - \", end=\"\")\n        with torch.no_grad():\n            val_loss = 0\n            for input, target in val:\n                output = model(input.cuda())\n                loss = loss_fn(output, target.view(-1, 1).to(torch.float32).cuda())\n                val_loss = val_loss + loss\n        print(\"Validation loss = \" + str(round(val_loss.item(), 2)))\n        checkpoint.step(model, val_loss.item())\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:11:45.466793Z","iopub.execute_input":"2022-02-01T19:11:45.467064Z","iopub.status.idle":"2022-02-01T19:11:45.482586Z","shell.execute_reply.started":"2022-02-01T19:11:45.467035Z","shell.execute_reply":"2022-02-01T19:11:45.481808Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"The fitting process is now launched using the Adam optimizer and 10 epochs.","metadata":{}},{"cell_type":"code","source":"optim = torch.optim.Adam(model.parameters(),lr=0.001)\nmodel = fit(model,optim,train,val)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:11:50.950358Z","iopub.execute_input":"2022-02-01T19:11:50.950642Z","iopub.status.idle":"2022-02-01T20:09:25.555001Z","shell.execute_reply.started":"2022-02-01T19:11:50.950610Z","shell.execute_reply":"2022-02-01T20:09:25.554257Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 5485.59 - Validation loss = 1419.67\nValidation loss improved from inf to 1419.67 ; current model saved to /kaggle/working/cnn.pkl\nEpoch 2 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 4434.61 - Validation loss = 1479.92\nEpoch 3 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 3974.79 - Validation loss = 1320.48\nValidation loss improved from 1419.67 to 1320.48 ; current model saved to /kaggle/working/cnn.pkl\nEpoch 4 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 3557.45 - Validation loss = 1075.33\nValidation loss improved from 1320.48 to 1075.33 ; current model saved to /kaggle/working/cnn.pkl\nEpoch 5 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 3229.12 - Validation loss = 986.16\nValidation loss improved from 1075.33 to 986.16 ; current model saved to /kaggle/working/cnn.pkl\nEpoch 6 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 3027.57 - Validation loss = 1045.69\nEpoch 7 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 2948.05 - Validation loss = 863.8\nValidation loss improved from 986.16 to 863.8 ; current model saved to /kaggle/working/cnn.pkl\nEpoch 8 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 2868.68 - Validation loss = 906.75\nEpoch 9 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 2685.12 - Validation loss = 893.4\nEpoch 10 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 2642.33 - Validation loss = 930.89\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The model has finished training itself. The best saved model is reloaded and used to predict the values on the evaluation sample to assess its performance.","metadata":{}},{"cell_type":"code","source":"model = torch.load(\"/kaggle/working/cnn.pkl\")\npred = []\nwith torch.no_grad():\n    for input, target in test:\n        output = model(input.cuda())\n        pred.append(output.cpu().numpy())\npred = np.vstack(pred)\nprint(pd.crosstab(traindata.test[1].values,pred.flatten()>0.5))        ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T20:19:12.579936Z","iopub.execute_input":"2022-02-01T20:19:12.580300Z","iopub.status.idle":"2022-02-01T20:19:54.979218Z","shell.execute_reply.started":"2022-02-01T20:19:12.580263Z","shell.execute_reply":"2022-02-01T20:19:54.978502Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"col_0  False  True\nrow_0             \n0       6394   104\n1        197   835\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The obtained results are quite satisfying: the true positive rate equals almost 81%, and the false positive rate is only 1.6%. However, there are still almost 20% melanoma which are misclassified. Misclassifying a melanoma as a non-melanoma can be considered to be a worse error than misclassifying a non-melanoma as a melanoma.\n\nThe 20% misclassified melanoma can be explained by the important imbalance between classes. Indeed, the non-melanoma are more than 6 times more numerous than the melanoma cases. Thus, the first class is favored over the second one in the training. To counteract this, we can use weights to rebalance the importance in favor of the melanoma class. When computing the loss value, each instance will be weighted depending on its class, and melanoma instances will have a higher contribution to the total loss. To efficiently reduce its loss, the model will have to improve itself on the melanoma class.\n\nThe weights are computed using the compute_class_weight function of the Scikit-Learn package. This function gives weights which enable to restore equivalent importance among classes. Everything else in the training process is kept unchanged.","metadata":{}},{"cell_type":"code","source":"model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\nmodel.fc = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2048,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nmodel.cuda()\n\noptim = torch.optim.Adam(model.parameters(),lr=0.001)\n\nfrom sklearn.utils.class_weight import compute_class_weight\nw = compute_class_weight(class_weight=\"balanced\", y=traindata.train[1], classes=[0, 1])\n\ndef fit_weighted(model,optim,train,val,weights,n_epochs=10,file_save=\"/kaggle/working/cnn_weighted.pkl\"):\n    def make_weight_tensor(ybatch,w0,w1):\n        w = np.zeros_like(ybatch)\n        w[np.where(ybatch.numpy()==1)[0]] = w1\n        w[np.where(ybatch.numpy()==0)[0]] = w0\n        return torch.tensor(w)\n    checkpoint = ModelCheckpoint(file_save=file_save)\n    loss_fn = torch.nn.BCELoss(reduction=\"none\")\n    for i in range(n_epochs):\n        print(\"Epoch \" + str(i + 1) + \" - \", end=\"\")\n        train_loss = 0\n        k = 0\n        for input, target in train:\n            k = k + 1\n            if k % 500 == 0:\n                print(str(round(k * 100 / len(train), 2)) + \"% - \", end=\"\")\n            optim.zero_grad()\n            output = model(input.cuda())\n            target = target.view(-1, 1).to(torch.float32)\n            loss = loss_fn(output, target.cuda())\n            loss = torch.sum(loss*make_weight_tensor(target,w[0],w[1]).cuda())\n            loss.backward()\n            optim.step()\n            train_loss = train_loss + loss\n        print(\"Training loss = \" + str(round(train_loss.item(), 2)) + \" - \", end=\"\")\n        with torch.no_grad():\n            val_loss = 0\n            yy = []\n            pred = []\n            for input, target in val:\n                output = model(input.cuda())\n                target = target.view(-1, 1).to(torch.float32)\n                loss = loss_fn(output, target.cuda())\n                loss = torch.sum(loss * make_weight_tensor(target, w[0], w[1]).cuda())\n                val_loss = val_loss + loss\n            print(\"Validation loss = \" + str(round(val_loss.item(), 2)))\n        checkpoint.step(model, val_loss.item())\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-01T20:19:58.898114Z","iopub.execute_input":"2022-02-01T20:19:58.898457Z","iopub.status.idle":"2022-02-01T20:19:59.527655Z","shell.execute_reply.started":"2022-02-01T20:19:58.898418Z","shell.execute_reply":"2022-02-01T20:19:59.526837Z"},"_kg_hide-input":true,"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model = fit_weighted(model,optim,train,val,w)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T20:20:04.449745Z","iopub.execute_input":"2022-02-01T20:20:04.450511Z","iopub.status.idle":"2022-02-01T21:15:56.311166Z","shell.execute_reply.started":"2022-02-01T20:20:04.450461Z","shell.execute_reply":"2022-02-01T21:15:56.310389Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 9209.89 - Validation loss = 2317.5\nValidation loss improved from inf to 2317.5 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 2 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 7410.61 - Validation loss = 2277.67\nValidation loss improved from 2317.5 to 2277.67 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 3 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 6664.46 - Validation loss = 2072.84\nValidation loss improved from 2277.67 to 2072.84 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 4 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 6517.78 - Validation loss = 2036.94\nValidation loss improved from 2072.84 to 2036.94 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 5 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 6090.95 - Validation loss = 2030.65\nValidation loss improved from 2036.94 to 2030.65 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 6 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 5961.9 - Validation loss = 1820.96\nValidation loss improved from 2030.65 to 1820.96 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 7 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 5772.62 - Validation loss = 2011.34\nEpoch 8 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 5595.58 - Validation loss = 1723.94\nValidation loss improved from 1820.96 to 1723.94 ; current model saved to /kaggle/working/cnn_weighted.pkl\nEpoch 9 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 5388.69 - Validation loss = 1828.49\nEpoch 10 - 17.71% - 35.41% - 53.12% - 70.82% - 88.53% - Training loss = 5359.07 - Validation loss = 1906.51\n","output_type":"stream"}]},{"cell_type":"code","source":"model = torch.load(\"/kaggle/working/cnn_weighted.pkl\")\npred = []\nwith torch.no_grad():\n    for input, target in test:\n        output = model(input.cuda())\n        pred.append(output.cpu().numpy())\npred = np.vstack(pred)\nprint(pd.crosstab(traindata.test[1].values,pred.flatten()>0.5))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:17:44.397273Z","iopub.execute_input":"2022-02-01T21:17:44.397661Z","iopub.status.idle":"2022-02-01T21:18:26.081349Z","shell.execute_reply.started":"2022-02-01T21:17:44.397615Z","shell.execute_reply":"2022-02-01T21:18:26.080565Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"col_0  False  True\nrow_0             \n0       6036   462\n1        116   916\n","output_type":"stream"}]},{"cell_type":"markdown","source":"A great improvement is obtained here: the model now successfully identifies 89% of the melanoma. The number of melanoma correctly identified has improved by almost 10%. On the other hand, the false positive rate has increased to 7%, which was expected.\n\nThe algorithm could probably be further improved. For instance, more epochs could be used to train it. Moreover, learning rate scheduling procedures could be used, to adjust the learning rate value during training. Finally, the probability threshold could be properly tuned, instead of arbitrarily chosen to be 0.5. For instance, using the precision-recall curve enables to determine the threshold maximizing the F1-score. Another strategy could be to choose the threshold maximizing the true positive rate, while maintaining the precision over a given value.","metadata":{}}]}
